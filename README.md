# Security & Privacy in AIGC
A list of research towards security & privacy in AI-Generated Content.  
Sorted by the appearance on [arXiv](https://arxiv.org/).

<!-- 
Template
+ [**title**](link)  
<font face="Calibri">*authors*</font> 
-->

### Survey

+ [**Security and Privacy on Generative Data in AIGC: A Survey**](https://arxiv.org/abs/2309.09435)  
<font face="Calibri">*Tao Wang, Yushu Zhang, Shuren Qi, Ruoyu Zhao, Zhihua Xia, Jian Weng*</font> 

+ [**On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey**](https://arxiv.org/abs/2307.16680)  
<font face="Calibri">*Mingyuan Fan, Cen Chen, Chengyu Wang, Jun Huang*</font>

<!-- 
Template
+ [**title**](link)  
<font face="Calibri">*authors*</font> 
-->

### Perturbations for Image Protection

+ arXiv:2404.15081 [**Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging Perturbations That Efficiently Fool Customized Diffusion Models**](https://arxiv.org/abs/2404.15081)  
<font face="Calibri">*Jingyao Xu, Yuetong Lu, Yandong Li, Siyang Lu, Dongdong Wang, Xiang Wei*</font> 

+ arXiv:2310.19248 [**IMPRESS: Evaluating the Resilience of Imperceptible Perturbations Against Unauthorized Data Usage in Diffusion-Based Generative AI**](https://arxiv.org/abs/2310.19248)  
<font face="Calibri">*Bochuan Cao, Changjiang Li, Ting Wang, Jinyuan Jia, Bo Li, Jinghui Chen*</font> 

+ arXiv:2309.11575 [**Distilling Adversarial Prompts from Safety Benchmarks: Report for the Adversarial Nibbler Challenge**](https://arxiv.org/abs/2309.11575)  
<font face="Calibri">*Manuel Brack, Patrick Schramowski, Kristian Kersting*</font> 

+ arXiv:2308.14761 [**Unified Concept Editing in Diffusion Models**](https://arxiv.org/abs/2308.14761)  
<font face="Calibri">*Rohit Gandikota, Hadas Orgad, Yonatan Belinkov, Joanna Materzyńska, David Bau*</font> 

+ arXiv:2308.10718 [**Backdooring Textual Inversion for Concept Censorship**](https://arxiv.org/abs/2308.10718)  
<font face="Calibri">*Yutong Wu, Jie Zhang, Florian Kerschbaum, Tianwei Zhang*</font> 

+ arXiv:2308.01937 [**Training Data Protection with Compositional Diffusion Models**](https://arxiv.org/abs/2308.01937)  
<font face="Calibri">*Aditya Golatkar, Alessandro Achille, Ashwin Swaminathan, Stefano Soatto*</font> 

+ arXiv:2308.04448 [**Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI**](https://arxiv.org/abs/2308.04448)  
<font face="Calibri">*Avijit Ghosh, Dhanya Lakshmi*</font> 

+ arXiv:2307.16680 [**On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey**](https://arxiv.org/abs/2307.16680)  
<font face="Calibri">*Mingyuan Fan, Cen Chen, Chengyu Wang, Jun Huang*</font>

+ arXiv:2307.13527 [**Not with my name! Inferring artists' names of input strings employed by Diffusion Models**](https://arxiv.org/abs/2307.13527)  
<font face="Calibri">*Roberto Leotta, Oliver Giudice, Luca Guarnera, Sebastiano Battiato*</font>

+ arXiv:2307.12872 [**Data-free Black-box Attack based on Diffusion Model**](https://arxiv.org/abs/2307.12872)  
<font face="Calibri">*Mingwen Shao, Lingzhuang Meng, Yuanjian Qiao, Lixu Zhang, Wangmeng Zuo*</font>

+ arXiv:2307.03108 [**How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models**](https://arxiv.org/abs/2307.03108)  
<font face="Calibri">*Zhenting Wang, Chen Chen, Yuchen Liu, Lingjuan Lyu, Dimitris Metaxas, Shiqing Ma*</font>

+ arXiv:2306.15774 [**Next Steps for Human-Centered Generative AI: A Technical Perspective**](https://arxiv.org/abs/2306.15774)  
<font face="Calibri">*Xiang 'Anthony' Chen, Jeff Burke, Ruofei Du, Matthew K. Hong, Jennifer Jacobs, Philippe Laban, Dingzeyu Li, Nanyun Peng, Karl D. D. Willis, Chien-Sheng Wu, Bolei Zhou*</font>

+ arXiv:2306.09776 [**Inspire Creativity with ORIBA: Transform Artists' Original Characters into Chatbots through Large Language Model**](https://arxiv.org/abs/2306.09776)  
<font face="Calibri">*Yuqian Sun, Xingyu Li, Ze Gao*</font>

+ arXiv:2306.08310 [**TWIGMA: A dataset of AI-Generated Images with Metadata From Twitter**](https://arxiv.org/abs/2306.08310)  
<font face="Calibri">*Yiqun Chen, James Zou*</font>

+ arXiv:2306.08257 [**On the Robustness of Latent Diffusion Models**](https://arxiv.org/abs/2306.08257)  
<font face="Calibri">*Jianping Zhang, Zhuoer Xu, Shiwen Cui, Changhua Meng, Weibin Wu, Michael R. Lyu*</font>

+ arXiv:2306.07754 [**Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis**](https://arxiv.org/abs/2306.07754)  
<font face="Calibri">*Yihan Ma, Zhengyu Zhao, Xinlei He, Zheng Li, Michael Backes, Yang Zhang*</font>

+ arXiv:2306.05949 [**Evaluating the Social Impact of Generative AI Systems in Systems and Society**](https://arxiv.org/abs/2306.05949)  
<font face="Calibri">*Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker, Su Lin Blodgett, Hal Daumé III, Jesse Dodge, Ellie Evans, Sara Hooker, Yacine Jernite, Alexandra Sasha Luccioni, Alberto Lusoli, Margaret Mitchell, Jessica Newman, Marie-Therese Png, Andrew Strait, Apostol Vassilev*</font>

+ arXiv:2306.04141 [**Art and the science of generative AI: A deeper dive**](https://arxiv.org/abs/2306.04141)  
<font face="Calibri">*Ziv Epstein, Aaron Hertzmann, Laura Herman, Robert Mahari, Morgan R. Frank, Matthew Groh, Hope Schroeder, Amy Smith, Memo Akten, Jessica Fjeld, Hany Farid, Neil Leach, Alex Pentland, Olga Russakovsky*</font>

+ arXiv:2306.01902 [**Unlearnable Examples for Diffusion Models: Protect Data from Unauthorized Exploitation**](https://arxiv.org/abs/2306.01902)  
<font face="Calibri">*Zhengyue Zhao, Jinhao Duan, Xing Hu, Kaidi Xu, Chenan Wang, Rui Zhang, Zidong Du, Qi Guo, Yunji Chen*</font>

+ arXiv:2306.00080 [**AI Imagery and the Overton Window**](https://arxiv.org/abs/2306.00080)  
<font face="Calibri">*Sarah K. Amer*</font>

+ arXiv:2306.00419 [**Challenges and Remedies to Privacy and Security in AIGC: Exploring the Potential of Privacy Computing, Blockchain, and Beyond**](https://arxiv.org/abs/2306.00419)  
<font face="Calibri">*Chuan Chen, Zhenpeng Wu, Yanyi Lai, Wenlin Ou, Tianchi Liao, Zibin Zheng*</font>

+ arXiv:2305.18615 [**Stronger Together: on the Articulation of Ethical Charters, Legal Tools, and Technical Documentation in ML**](https://arxiv.org/abs/2305.18615)  
<font face="Calibri">*Giada Pistilli, Carlos Munoz Ferrandis, Yacine Jernite, Margaret Mitchell*</font>

+ arXiv:2305.16934 [**On Evaluating Adversarial Robustness of Large Vision-Language Models**](https://arxiv.org/abs/2305.16934)  
<font face="Calibri">*Yunqing Zhao, Tianyu Pang, Chao Du, Xiao Yang, Chongxuan Li, Ngai-Man Cheung, Min Lin*</font>

+ arXiv:2305.13238 [**The Dimensions of Data Labor: A Road Map for Researchers, Activists, and Policymakers to Empower Data Producers**](https://arxiv.org/abs/2305.13238)  
<font face="Calibri">*Hanlin Li, Nicholas Vincent, Stevie Chancellor, Brent Hecht*</font>

+ arXiv:2305.12683 [**Mist: Towards Improved Adversarial Examples for Diffusion Models**](https://arxiv.org/abs/2305.12683)  
<font face="Calibri">*Chumeng Liang, Xiaoyu Wu*</font>

+ arXiv:2305.12502 [**Watermarking Diffusion Model**](https://arxiv.org/abs/2305.12502)  
<font face="Calibri">*Yugeng Liu, Zheng Li, Michael Backes, Yun Shen, Yang Zhang*</font>

+ arXiv:2305.12015 [**Inventing painting styles through natural inspiration**](https://arxiv.org/abs/2305.12015)  
<font face="Calibri">*Nilin Abrahamsen, Jiahao Yao*</font>

+ arXiv:2304.03545 [**AI Model Disgorgement: Methods and Choices**](https://arxiv.org/abs/2304.03545)  
<font face="Calibri">*Alessandro Achille, Michael Kearns, Carson Klingenberg, Stefano Soatto*</font>

+ arXiv:2304.02234 [**JPEG Compressed Images Can Bypass Protections Against AI Editing**](https://arxiv.org/abs/2304.02234)  
<font face="Calibri">*Pedro Sandoval-Segura, Jonas Geiping, Tom Goldstein*</font>

+ arXiv:2303.16378 [**A Pilot Study of Query-Free Adversarial Attack against Stable Diffusion**](https://arxiv.org/abs/2303.16378)  
<font face="Calibri">*Haomin Zhuang, Yihua Zhang, Sijia Liu*</font>

+ arXiv:2303.15433 [**Anti-DreamBooth: Protecting users from personalized text-to-image synthesis**](https://arxiv.org/abs/2303.15433)  
<font face="Calibri">*Thanh Van Le, Hao Phung, Thuan Hoang Nguyen, Quan Dao, Ngoc Tran, Anh Tran*</font>

+ arXiv:2303.13516 [**Ablating Concepts in Text-to-Image Diffusion Models**](https://arxiv.org/abs/2303.13516)  
<font face="Calibri">*Nupur Kumari, Bingliang Zhang, Sheng-Yu Wang, Eli Shechtman, Richard Zhang, Jun-Yan Zhu*</font>

+ arXiv:2303.07345 [**Erasing Concepts from Diffusion Models**](https://arxiv.org/abs/2303.07345)  
<font face="Calibri">*Rohit Gandikota, Joanna Materzynska, Jaden Fiotto-Kaufman, David Bau*</font>

+ arXiv:2302.06588 [**Raising the Cost of Malicious AI-Powered Image Editing**](https://arxiv.org/abs/2302.06588). *ICML 2023*   
<font face="Calibri">*Hadi Salman, Alaa Khaddaj, Guillaume Leclerc, Andrew Ilyas, Aleksander Madry*</font>

+ arXiv:2302.04578 [**Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples**](https://arxiv.org/abs/2302.04578). *ICML 2023*   
<font face="Calibri">*Chumeng Liang, Xiaoyu Wu, Yang Hua, Jiaru Zhang, Yiming Xue, Tao Song, Zhengui Xue, Ruhui Ma, Haibing Guan*</font>

+ arXiv:2302.04222 [**GLAZE: Protecting Artists from Style Mimicry by Text-to-Image Models**](https://arxiv.org/abs/2302.04222). *USENIX Security 2023*  
<font face="Calibri">*Shawn Shan, Jenna Cryan, Emily Wenger, Haitao Zheng, Rana Hanocka, Ben Y. Zhao*</font>

+ arXiv:2212.03860 [**Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models**](https://arxiv.org/abs/2212.03860)  
<font face="Calibri">*Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, Tom Goldstein*</font>


<!-- 
Template
+ [**title**](link)  
<font face="Calibri">*authors*</font> 
-->

### Watermark

+ arXiv:2405.02365 [**Adaptive and robust watermark against model extraction attack**](https://arxiv.org/abs/2405.02365)  
<font face="Calibri">*Kaiyi Pang, Tao Qi, Chuhan Wu, Minhao Bai*</font> 

+ arXiv:2311.12832 [**Toward effective protection against diffusion-based mimicry through score distillation**](https://arxiv.org/abs/2311.12832)  *ICLR2024*  
<Font face='Calibri'>*Haotian Xue, Chumeng Liang, Xiaoyu Wu, Yongxin Chen*</font>

+ arXiv:2404.13518 [**Reliable Model Watermarking: Defending Against Theft without Compromising on Evasion**](https://arxiv.org/abs/2404.13518)  
<font face="Calibri">*Hongyu Zhu, Sichu Liang, Wentao Hu, Fangqi Li, Ju Jia, Shilin Wang*</font> 

+ arXiv:2404.04956 [**Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models**](https://arxiv.org/abs/2404.04956)  
<font face="Calibri">*Zijin Yang, Kai Zeng, Kejiang Chen, Han Fang, Weiming Zhang, Nenghai Yu*</font> 

+ arXiv:2403.10893 [**A Watermark-Conditioned Diffusion Model for IP Protection**](https://arxiv.org/abs/2403.10893)  
<font face="Calibri">*Rui Min, Sen Li, Hongyang Chen, Minhao Cheng*</font> 

+ arXiv:2401.08573 [**Benchmarking the Robustness of Image Watermarks**](https://arxiv.org/abs/2401.08573)  
<font face="Calibri">*Bang An, Mucong Ding, Tahseen Rabbani, Aakriti Agrawal, Yuancheng Xu, Chenghao Deng, Sicheng Zhu, Abdirisak Mohamed, Yuxin Wen, Tom Goldstein, Furong Huang*</font> 

+ arXiv:2312.08883 [**EditGuard: Versatile Image Watermarking for Tamper Localization and Copyright Protection**](https://arxiv.org/abs/2312.08883) *CVPR 2024*  
<font face="Calibri">*Xuanyu Zhang, Runyi Li, Jiwen Yu, Youmin Xu, Weiqi Li, Jian Zhang*</font> 

+ arXiv:2311.13713 [**A Somewhat Robust Image Watermark against Diffusion-based Editing Models**](https://arxiv.org/abs/2311.13713)  
<font face="Calibri">*Mingtian Tan, Tianhao Wang, Somesh Jha*</font> 

+ arXiv:2310.07726 [**Warfare:Breaking the Watermark Protection of AI-Generated Content**](https://arxiv.org/abs/2310.07726)  
<font face="Calibri">*Guanlin Li, Yifei Chen, Jie Zhang, Jiwei Li, Shangwei Guo, Tianwei Zhang*</font> 

+ arXiv:2309.16952 [**Leveraging Optimization for Adaptive Attacks on Image Watermarks**](https://arxiv.org/abs/2309.16952) *ICLR 2024*  
<font face="Calibri">*Nils Lukas, Abdulrahman Diaa, Lucas Fenaux, Florian Kerschbaum*</font> 

+ arXiv:2309.05940 [**Catch You Everything Everywhere: Guarding Textual Inversion via Concept Watermarking**](https://arxiv.org/abs/2309.05940)  
<font face="Calibri">*Weitao Feng, Jiyan He, Jie Zhang, Tianwei Zhang, Wenbo Zhou, Weiming Zhang, Nenghai Yu*</font> 

+ arXiv:2306.03436 [**Intellectual Property Protection of Diffusion Models via the Watermark Diffusion Process**](https://arxiv.org/abs/2306.03436)  
<font face="Calibri">*Sen Peng, Yufei Chen, Cong Wang, Xiaohua Jia*</font>

+ arXiv:2306.04642 [**DiffusionShield: A Watermark for Copyright Protection against Generative Diffusion Models**](https://arxiv.org/abs/2306.04642)  
<font face="Calibri">*Yingqian Cui, Jie Ren, Han Xu, Pengfei He, Hui Liu, Lichao Sun, Yue Xing, Jiliang Tang*</font>

+ arXiv:2306.01953 [**Invisible Image Watermarks Are Provably Removable Using Generative AI**](https://arxiv.org/abs/2306.01953)  
<font face="Calibri">*Xuandong Zhao, Kexun Zhang, Zihao Su, Saastha Vasan, Ilya Grishchenko, Christopher Kruegel, Giovanni Vigna, Yu-Xiang Wang, Lei Li*</font> 

+ arXiv:2305.20030 [**Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust**](https://arxiv.org/abs/2305.20030)  *NeurIPS 2023*  
<font face="Calibri">*Yuxin Wen, John Kirchenbauer, Jonas Geiping, Tom Goldstein*</font> 

+ arXiv:2305.03807 [**Evading Watermark based Detection of AI-Generated Content**](https://arxiv.org/abs/2305.03807)  
<font face="Calibri">*Zhengyuan Jiang, Jinghuai Zhang, Neil Zhenqiang Gong*</font> 

+ arXiv:2303.15435 [**The Stable Signature: Rooting Watermarks in Latent Diffusion Models**](https://arxiv.org/abs/2303.15435) *ICCV 2023*  
<font face="Calibri">*Pierre Fernandez, Guillaume Couairon, Hervé Jégou, Matthijs Douze, Teddy Furon*</font>

+ arXiv:2303.10137 [**A Recipe for Watermarking Diffusion Models**](https://arxiv.org/abs/2303.10137)  
<font face="Calibri">*Yunqing Zhao, Tianyu Pang, Chao Du, Xiao Yang, Ngai-Man Cheung, Min Lin*</font> 

+ arXiv:2209.03466 [**Supervised GAN Watermarking for Intellectual Property Protection**](https://arxiv.org/abs/2209.03466)  
<font face="Calibri">*Jianwei Fei, Zhihua Xia, Benedetta Tondi, Mauro Barni*</font> 

+ arXiv:2102.04362 [**Protecting Intellectual Property of Generative Adversarial Networks from Ambiguity Attack**](https://arxiv.org/abs/2102.04362)  *CVPR 2021*   
<font face="Calibri">*Ding Sheng Ong, Chee Seng Chan, Kam Woh Ng, Lixin Fan, Qiang Yang*</font> 

+ arXiv:2007.08457 [**Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data**](https://arxiv.org/abs/2007.08457)  *ICCV 2021*  
<font face="Calibri">*Ning Yu, Vladislav Skripniuk, Sahar Abdelnabi, Mario Fritz*</font> 

<!-- 
Template
+ [**title**](link)  
<font face="Calibri">*authors*</font> 
-->

### Membership Inference Attack

+ arXiv:2312.08207 [**Black-box Membership Inference Attacks against Fine-tuned Diffusion Models**](https://arxiv.org/abs/2312.08207)  
<font face="Calibri">*Yan Pang, Tianhao Wang*</font> 

+ arXiv:2312.05140 [**Membership Inference Attacks on Diffusion Models via Quantile Regression**](https://arxiv.org/abs/2312.05140)  
<font face="Calibri">*Shuai Tang, Zhiwei Steven Wu, Sergul Aydore, Michael Kearns, Aaron Roth*</font> 

+ arXiv:2308.12143 [**A Probabilistic Fluctuation based Membership Inference Attack for Diffusion Models**](https://arxiv.org/abs/2308.12143)  
<font face="Calibri">*Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang*</font> 

+ arXiv:2308.06405 [**White-box Membership Inference Attacks against Diffusion Models**](https://arxiv.org/abs/2308.06405)  
<font face="Calibri">*Yan Pang, Tianhao Wang, Xuhui Kang, Mengdi Huai, Yang Zhang*</font> 

+ arXiv:2306.12983 [**Towards More Realistic Membership Inference Attacks on Large Diffusion Models**](https://arxiv.org/abs/2306.12983)  
<font face="Calibri">*Jan Dubiński, Antoni Kowalczuk, Stanisław Pawlak, Przemysław Rokita, Tomasz Trzciński, Paweł Morawiecki*</font> 

+ arXiv:2305.18355 [**An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization**](https://arxiv.org/abs/2305.18355)  
<font face="Calibri">*Fei Kong, Jinhao Duan, RuiPeng Ma, Hengtao Shen, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu*</font> 

+ arXiv:2305.08694 [**A Reproducible Extraction of Training Images from Diffusion Models**](https://arxiv.org/abs/2305.08694)  
<font face="Calibri">*Ryan Webster*</font> 

+ arXiv:2302.07801 [**Data Forensics in Diffusion Models: A Systematic Analysis of Membership Privacy**](https://arxiv.org/abs/2302.07801)  
<font face="Calibri">*Derui Zhu, Dingfan Chen, Jens Grossklags, Mario Fritz*</font> 

+ arXiv:2302.03262 [**Membership Inference Attacks against Diffusion Models**](https://arxiv.org/abs/2302.03262)  
<font face="Calibri">*Tomoya Matsumoto, Takayuki Miura, Naoto Yanai*</font>

+ arXiv:2302.01316 [**Are Diffusion Models Vulnerable to Membership Inference Attacks?**](https://arxiv.org/abs/2302.01316)
<font face="Calibri">*Jinhao Duan, Fei Kong, Shiqi Wang, Xiaoshuang Shi, Kaidi Xu*</font>

+ arXiv:2301.13188 [**Extracting Training Data from Diffusion Models**](https://arxiv.org/abs/2301.13188)  
<font face="Calibri">*Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, Eric Wallace*</font>

+ arXiv:2301.09956 [**Membership Inference of Diffusion Models**](https://arxiv.org/abs/2301.09956)  
<font face="Calibri">*Hailong Hu, Jun Pang*</font>

+ arXiv:2210.00968 [**Membership Inference Attacks Against Text-to-image Generation Models**](https://arxiv.org/abs/2210.00968)  
<font face="Calibri">*Yixin Wu, Ning Yu, Zheng Li, Michael Backes, Yang Zhang*</font>


<!-- 
Template
+ [**title**](link)  
<font face="Calibri">*authors*</font> 
-->

### Multimodal Foundation Modal

+ arXiv:2402.08577 [**Test-Time Backdoor Attacks on Multimodal Large Language Models**](https://arxiv.org/abs/2402.08577)  
<font face="Calibri">*Dong Lu, Tianyu Pang, Chao Du, Qian Liu, Xianjun Yang, Min Lin*</font> 

+ arXiv:2309.11751 [**How Robust is Google's Bard to Adversarial Image Attacks?**](https://arxiv.org/abs/2309.11751)  
<font face="Calibri">*Yinpeng Dong, Huanran Chen, Jiawei Chen, Zhengwei Fang, Xiao Yang, Yichi Zhang, Yu Tian, Hang Su, Jun Zhu*</font>

+ arXiv:2308.10741 [**On the Adversarial Robustness of Multi-Modal Foundation Models**](https://arxiv.org/abs/2308.10741)  
<font face="Calibri">*Christian Schlarmann, Matthias Hein*</font> 

+ arXiv:2306.13213 [**Visual Adversarial Examples Jailbreak Aligned Large Language Models**](https://arxiv.org/abs/2306.13213)  
<font face="Calibri">*Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Peter Henderson, Mengdi Wang, Prateek Mittal*</font> 

+ arXiv:2305.16934 [**On Evaluating Adversarial Robustness of Large Vision-Language Models**](https://arxiv.org/abs/2305.16934)  
<font face="Calibri">*Yunqing Zhao, Tianyu Pang, Chao Du, Xiao Yang, Chongxuan Li, Ngai-Man Cheung, Min Lin*</font> 